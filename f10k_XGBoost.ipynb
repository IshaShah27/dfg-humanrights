{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"f10k_XGBoost.ipynb","provenance":[{"file_id":"1s_CXMiFsVCo8Dj8CIf8IrTPTaWcAxtJG","timestamp":1599059463988}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"H0bmh0p-ae69","colab_type":"text"},"source":["## XGBoost model on 10Ks\n","Summary: Using XGBoost (not blended with any other models) to build a simple relevance classifier that indicates whether an excerpt in the SASB dataset is or is not an HCM-related disclosure. Success is moderate - when maximizing for recall, we get about 93% recall and about 64% precision.  \n","\n","**Next steps:**\n","1. Refine classifier to get higher precision with same level or better recall\n","2. Or, create a cascade of weak models\n","3. Once relevance meets our recall and precision threshold, take positive cases and build multiclass classifier on those\n","4. Collect and clean new 10-Ks; apply classifier to this new dataset\n","5. Visualize the share of excerpts that are positive for relevance for each industry, including those that do not have HCM materiality in 2018 standards"]},{"cell_type":"code","metadata":{"id":"B4610MFYV0wP","colab_type":"code","colab":{}},"source":["# Import basic libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib as plt\n","%matplotlib inline\n","import os\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktt39ONCV0xA","colab_type":"code","colab":{}},"source":["# Import json file from SASB\n","path = \"/Users/ishashah/Documents/DFG/dfg-humanrights0/from-sasb\"\n","os.chdir(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"te_ihhw_V0xy","colab_type":"code","colab":{}},"source":["json = pd.read_json(\"di_hc_rel_train.json\")\n","json.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DG_4K5MHV0yN","colab_type":"code","colab":{}},"source":["# Import csv lookup\n","toplabel = pd.read_csv(\"disclosure_topic.csv\")\n","toplabel.columns = map(str.lower, toplabel.columns)\n","toplabel.head()\n","\n","# How many are related to labor?\n","labor = toplabel[toplabel[\"disclosure_topic_name\"].str.contains(\"labor\", case = False) ]\n","labor\n","\n","# Create new label that flags labor only\n","toplabel[\"disclosure_islabor\"] = toplabel[\"disclosure_topic_name\"].str.contains(\"labor\", case = False)\n","toplabel.head()\n","json = pd.merge(json, toplabel, how = \"left\",\n","                on = \"disclosure_topic_id\")\n","json.columns\n","json.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nhxK3iW3V0zF","colab_type":"code","colab":{}},"source":["# Keep all output\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1AisxaoV00A","colab_type":"code","colab":{}},"source":["# Check excerpts more closely\n","pd.options.display.max_colwidth = 500\n","json[\"excerpt\"].head()\n","\n","# Are there any duplicates in text, in excerpt_id?\n","json.shape\n","json.drop_duplicates(\"excerpt\").shape\n","json.drop_duplicates(\"excerpt_id\").shape\n","# So, there are duplicates in text but not in excerpt_id\n","\n","# What proportion are quality_assessment, relevance_assessment categories?\n","json.columns\n","json.groupby(\"relevance_assessment\").agg(\"count\")\n","json.groupby(\"source_document\").agg(\"count\")\n","# Comes from more than one source document - keep all, even the ones that are\n","# not 10-Ks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ui56F8u7V00W","colab_type":"code","colab":{}},"source":["# Figuring out why there are certain exerpts marked with disclosure labels that have\n","# \"No disclosure\" relevance assessments\n","json[\"disclosure_topic_name\"].value_counts()\n","json[\"relevance_assessment\"].value_counts()\n","\n","json[(json[\"relevance_assessment\"] == \"No Disclosure\") & (json[\"disclosure_islabor\"])][\"excerpt\"].tail()\n","json[(json[\"relevance_assessment\"] == \"Relevant\") & (json[\"disclosure_islabor\"])][\"excerpt\"].tail()\n","# From these, it looks like we will have to use only those\n","# excerpts which are both marked Relevant and where disclosure topic is related to labor - \n","# If we include where the disclosure topic is related to labor and No Disclosure, then\n","# it looks like we'll get irrelevant entries\n","\n","# Create a flag for these\n","json[\"relevant_islabor\"] = ((json[\"disclosure_islabor\"]) & (json[\"relevance_assessment\"] == \"Relevant\"))\n","json[\"relevant_islabor\"].value_counts()\n","# Amounts to about 10% of dataset\n","\n","# See what the breakdown is of sub-topics within this\n","json[json[\"relevant_islabor\"]][\"disclosure_topic_name\"].value_counts()\n","# 75% are labor practices, around 20% are labor relations, 5% labor conditions\n","json[json[\"disclosure_islabor\"]][\"disclosure_topic_name\"].value_counts()\n","# Breakdown is about the same when including all excerpts labeled as related, not just those\n","# that are relevant\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6ssVoM0V00h","colab_type":"code","colab":{}},"source":["# Import libraries to handle text\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.stem.porter import PorterStemmer\n","from nltk.corpus import stopwords\n","\n","from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n","from sklearn.preprocessing import normalize\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHro-C8vV01w","colab_type":"code","colab":{}},"source":["# Preprocess 10K text similarly to proxy statements\n","\n","# Cleaning function\n","stopset = set(stopwords.words(\"english\"))\n","stemmer = PorterStemmer()\n","\n","def clean_text(in_text):\n","    # Remove line breaks\n","    text = in_text.replace(r'\\\\n', ' ')\n","    \n","    # Lowercase\n","    text = word_tokenize(re.sub('[^A-z ]+', '', text.lower()))\n","    \n","    # Remove stopwords, remove numbers and punctuation, stem\n","    text = [stemmer.stem(w) for w in text if w.isalpha() and w not in stopset]\n","    \n","    # Return joined version\n","    text = (\" \".join(text))\n","    \n","    return text\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXWiXzQMV013","colab_type":"code","colab":{}},"source":["# Progress tracker\n","\n","from tqdm import tqdm\n","from tqdm.notebook import tqdm_notebook\n","\n","tqdm_notebook.pandas()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCnb3fWWV02Q","colab_type":"code","colab":{}},"source":["# Apply cleaning function to json file text\n","json[\"clean_text\"] = json[\"excerpt\"].progress_apply(clean_text)\n","\n","json.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"csqfQ3Y5V02q","colab_type":"code","colab":{}},"source":["# Export csv of cleaned dataset\n","json.to_csv(\"json_clean.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QyS32c8V03A","colab_type":"code","colab":{}},"source":["# Import csv of cleaned dataset\n","json = pd.read_csv(\"json_clean.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TAc02uAV03I","colab_type":"code","colab":{}},"source":["# Check value counts for HCM flag\n","json[\"relevance_assessment\"].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXxitjj9V03q","colab_type":"code","colab":{}},"source":["# Import libraries to model, create word embeddings\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV, \\\n","StratifiedKFold, cross_val_predict, \\\n","StratifiedShuffleSplit\n","from sklearn.feature_selection import chi2\n","from sklearn.metrics import roc_curve, \\\n","precision_recall_curve, auc, make_scorer, \\\n","recall_score, accuracy_score, precision_score, \\\n","confusion_matrix, classification_report, roc_auc_score\n","\n","from gensim.models import Word2Vec, KeyedVectors\n","import gensim "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vo7Jokr7V04D","colab_type":"code","colab":{}},"source":["# Create list of cleaned words in each excerpt\n","json[\"cleantext_list\"] = json[\"clean_text\"].apply(lambda x: ','.join(word_tokenize(x)))\n","sent = [row.split(',') for row in json[\"cleantext_list\"]]\n","\n","# Train on corpus\n","model = Word2Vec(sent, min_count=5, size= 300,workers=3, window =3, sg = 1)\n","\n","# Check vector size\n","model.vector_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWPLmhT8V05c","colab_type":"code","colab":{}},"source":["#  Save trained word embeddings\n","model.wv.save_word2vec_format('model.txt', binary=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QQz_QVJkV05m","colab_type":"code","colab":{}},"source":["# Load trained word embeddings\n","model = KeyedVectors.load_word2vec_format('model.txt', binary=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOHHmKWcV05_","colab_type":"code","colab":{}},"source":["# Vectorize using trained word embeddings\n","import numpy as np\n","\n","def sent_vectorizer(sent, model):\n","    sent_vec =[]\n","    numw = 0\n","    for w in sent:\n","        try:\n","            if numw == 0:\n","                sent_vec = model[w]\n","            else:\n","                sent_vec = np.add(sent_vec, model[w])\n","            numw+=1\n","        except:\n","            pass\n","   \n","    return np.asarray(sent_vec) / numw\n","\n","\n","V=[]\n","\n","for sentence in sent:\n","    V.append(sent_vectorizer(sentence, model))   \n","    \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RNtgcp5V06P","colab_type":"code","colab":{}},"source":["# Join back to dataset\n","\n","json2 = pd.DataFrame(V, index = json['excerpt_id'])\n","json2 = json2.merge(right=json[[\"excerpt_id\", \"relevance_assessment\"]], \n","         left_index=True, right_on=\"excerpt_id\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8Na9Ot9V06V","colab_type":"code","colab":{}},"source":["# Save vectorized dataset\n","json2.to_csv(\"json2_clean.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvQGJxLrV06c","colab_type":"code","colab":{}},"source":["# Load vectorized dataset\n","json2 = pd.read_csv(\"json2_clean.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ujiKNVC7V07B","colab_type":"code","colab":{}},"source":["# Import XGboost, Keras for modeling\n","import xgboost as xgb\n","from sklearn.metrics import mean_squared_error, recall_score, precision_score\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3guX819aV07s","colab_type":"code","colab":{}},"source":["# Split X and y, convert to DMatrix\n","X = json2.iloc[:,0:300]\n","y = pd.DataFrame(pd.get_dummies(json2['relevance_assessment']))[\"Relevant\"]\n","\n","data_dmatrix = xgb.DMatrix(data=X,label=y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fw1UTZ5TV08K","colab_type":"code","colab":{}},"source":["# Train/test split\n","\n","# Set aside 20% for testing\n","X_train, X_test, y_train, y_test = train_test_split(X, \n","                                                    y, \n","                                                    test_size=0.20,\n","                                                    stratify = y,\n","                                                    random_state=8) \n","print(X_train.shape,y_train.shape)\n","print(X_test.shape,y_test.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M38F9XFQV08T","colab_type":"code","colab":{},"outputId":"f2588a1c-1801-4c09-a3f9-f4f027ea3169"},"source":["# Instantiate, fit, transform, XGB regressor\n","\n","# Instantiate\n","xg_class = xgb.XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n","                max_depth = 5, alpha = 10, n_estimators = 10)\n","\n","# Fit and predict on training only\n","xg_class.fit(X_train,y_train)\n","\n","preds = xg_class.predict(X_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n","       importance_type='gain', interaction_constraints='',\n","       learning_rate=0.1, max_delta_step=0, max_depth=5,\n","       min_child_weight=1, missing=nan, monotone_constraints='()',\n","       n_estimators=10, n_jobs=0, num_parallel_tree=1,\n","       objective='reg:logistic', random_state=0, reg_alpha=10,\n","       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n","       validate_parameters=1, verbosity=None)"]},"metadata":{"tags":[]},"execution_count":33},{"output_type":"stream","text":["/Users/ishashah/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n","  if diff:\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kihjEUN0V08q","colab_type":"code","colab":{},"outputId":"90218158-90cd-44d1-9ff6-c55d4f85ae97"},"source":["# Check accuracy without cross validation\n","print(\"Accuracy on test\\n\" , accuracy_score(y_test,preds))\n","print(\"Recall on test\\n\" , recall_score(y_test,preds))\n","print(\"Precision on test\\n\" , precision_score(y_test,preds))\n","\n","# Baseline is 77% accuracy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on test\n"," 0.7690256907416384\n","Recall on test\n"," 0.6955810147299509\n","Precision on test\n"," 0.7634730538922155\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XKNmi91dV08v","colab_type":"code","colab":{}},"source":["# Make train and test DMatrices\n","\n","dtrain = xgb.DMatrix(X_train, label=y_train)\n","dtest = xgb.DMatrix(X_test, label = y_test)\n","\n","X_test.shape\n","y_test.shape\n","dtest.num_row()\n","dtest.num_col()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4FG_s0uV09C","colab_type":"code","colab":{}},"source":["# Use gridsearch\n","\n","params = {\n","    'max_depth':6,\n","    'min_child_weight': 1,\n","    'eta':.3,\n","    'subsample': 1,\n","    'colsample_bytree': 1,\n","    'objective':'reg:logistic',\n","    'eval_metric':\"auc\"\n","}\n","\n","num_boost_round = 999\n","\n","# First check to see how optimal number of boosting rounds works\n","model = xgb.train(\n","    params,\n","    dtrain,\n","    num_boost_round=num_boost_round,\n","    evals=[(dtest, \"Test\")],\n","    early_stopping_rounds=10\n",")\n","\n","print(\"Best accuracy: {:.2f} with {} rounds\".format(\n","                 model.best_score,\n","                 model.best_iteration+1))\n","\n","# 0.85 with 31 rounds <- baseline + optimal number of boosting rounds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VV3OE58-V09N","colab_type":"code","colab":{}},"source":["# Tuning max_depth / min_child_weight\n","gridsearch_params = [\n","    (max_depth, min_child_weight)\n","    for max_depth in range(3,8)\n","    for min_child_weight in range(5,10,2)\n","]\n","\n","# Define initial best params and AUC\n","max_auc = 0\n","best_params = None\n","for max_depth, min_child_weight in gridsearch_params:\n","    print(\"CV with max_depth={}, min_child_weight={}\".format(\n","                             max_depth,\n","                             min_child_weight))\n","    params['max_depth'] = max_depth\n","    params['min_child_weight'] = min_child_weight\n","    # Run CV\n","    cv_results = xgb.cv(\n","        params,\n","        dtrain,\n","        num_boost_round=num_boost_round,\n","        seed=42,\n","        nfold=5,\n","        metrics={'auc'},\n","        early_stopping_rounds=10\n","    )\n","    # Update best AUC\n","    mean_auc = cv_results['test-auc-mean'].max()\n","    boost_rounds = cv_results['test-auc-mean'].argmax()\n","    print(\"\\tAUC {} for {} rounds\".format(mean_auc, boost_rounds))\n","    if mean_auc > max_auc:\n","        max_auc = mean_auc\n","        best_params = (max_depth,min_child_weight)\n","print(\"Best params: {}, {}, AUC: {}\".format(best_params[0], best_params[1], max_auc))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Zk3NAD3V09X","colab_type":"code","colab":{}},"source":["# Assign best min child weight and max depth to parameter grid\n","params['max_depth'] = best_params[0]\n","params['min_child_weight'] = best_params[1]\n","\n","# #0.8461913999999998"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y72tFo47V09g","colab_type":"code","colab":{}},"source":["# Tune subsample and colsample_bytree\n","gridsearch_params = [\n","    (subsample, colsample)\n","    for subsample in [i/10. for i in range(8,12,2)]\n","    for colsample in [i/10. for i in range(8,12,2)]\n","]\n","max_auc = 0\n","best_params = None\n","for subsample, colsample in reversed(gridsearch_params):\n","    print(\"CV with subsample={}, colsample={}\".format(\n","                             subsample,\n","                             colsample))\n","    params['subsample'] = subsample\n","    params['colsample_bytree'] = colsample\n","    # Run CV\n","    cv_results = xgb.cv(\n","        params,\n","        dtrain,\n","        num_boost_round=num_boost_round,\n","        seed=42,\n","        nfold=5,\n","        metrics={'auc'},\n","        early_stopping_rounds=10\n","    )\n","    # Update best score\n","    mean_auc = cv_results['test-auc-mean'].max()\n","    boost_rounds = cv_results['test-auc-mean'].argmax()\n","    print(\"\\tAUC {} for {} rounds\".format(mean_auc, boost_rounds))\n","    if mean_auc > max_auc:\n","        max_auc = mean_auc\n","        best_params = (subsample,colsample)\n","print(\"Best params: {}, {}, AUC: {}\".format(best_params[0], best_params[1], max_auc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUBFVcB9V09o","colab_type":"code","colab":{}},"source":["# Assign best subsample and col sample by tree to parameter grid\n","params['subsample'] = best_params[0]\n","params['colsample_bytree'] = best_params[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsxUjPTIV09w","colab_type":"code","colab":{}},"source":["# Tune eta (learning rate)\n","%time\n","\n","max_auc = 0\n","best_params = None\n","for eta in [.3, .2, .1, .05, .01, .005]:\n","    print(\"CV with eta={}\".format(eta))\n","    params['eta'] = eta\n","    # Run and time CV\n","    cv_results = xgb.cv(\n","        params,\n","        dtrain,\n","        num_boost_round=num_boost_round,\n","        seed=42,\n","        nfold=5,\n","        metrics=['auc'],\n","        early_stopping_rounds=10\n","      )\n","    # Update best score\n","    mean_auc = cv_results['test-auc-mean'].max()\n","    boost_rounds = cv_results['test-auc-mean'].argmax()\n","    print(\"\\tAUC {} for {} rounds\\n\".format(mean_auc, boost_rounds))\n","    if mean_auc > max_auc:\n","        max_auc = mean_auc\n","        best_params = eta\n","print(\"Best params: {}, AUC: {}\".format(best_params, max_auc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBmIEkU-V091","colab_type":"code","colab":{}},"source":["# Store chosen eta (actually running grid search took too long)\n","params['eta'] = 0.05"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KldMh-FV0-B","colab_type":"code","colab":{}},"source":["# Train model with optimal parameters\n","model = xgb.train(\n","    params,\n","    dtrain,\n","    num_boost_round=num_boost_round,\n","    evals=[(dtest, \"Test\")],\n","    early_stopping_rounds=10\n",")\n","\n","num_boost_round = model.best_iteration + 1\n","\n","best_model = xgb.train(\n","    params,\n","    dtrain,\n","    num_boost_round=num_boost_round,\n","    evals=[(dtest, \"Test\")]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzF-NNNj0PU8","colab_type":"code","colab":{}},"source":["# Save model\n","best_model.save_model(\"xgb_model.model\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XdbRFKDuV0-Q","colab_type":"code","colab":{}},"source":["# Predict on test dataset\n","test_pred = best_model.predict(dtest)\n","test_pred = pd.DataFrame(test_pred)\n","y_testdf = pd.DataFrame(y_test).reset_index()\n","test_pred = pd.concat([y_testdf, test_pred], axis = 1)\n","test_pred.head()\n","\n","# Choose 0.5 as threshold, standard \n","test_pred['pred'] = test_pred[0].apply(lambda x: 0 if x < 0.5 else 1)\n","test_pred = test_pred.set_index('index')\n","test_pred = pd.merge(test_pred, json[[\"excerpt\", \"relevance_assessment\"]], \n","                     left_index = True, right_index = True)\n","pd.set_option('max_colwidth', 350)\n","test_pred.head()\n","\n","print(\"On test:\")\n","print(\"Accuracy score is:\\n\", accuracy_score(test_pred['pred'], y_test))\n","print(\"AUC score is:\\n\", roc_auc_score(test_pred['pred'], y_test))\n","print(\"Recall score is:\\n\", recall_score(test_pred['pred'], y_test))\n","print(\"Precision score is:\\n\", precision_score(test_pred['pred'], y_test))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"geDBpwtwV0-i","colab_type":"code","colab":{},"outputId":"02371ebf-0f38-4b63-a6e2-f259413770b0"},"source":["# Change threshold to get recall up to 0.8 at least\n","test_pred['pred'] = test_pred[0].apply(lambda x: 0 if x < 0.2 else 1)\n","print(\"On test with lower threshold:\")\n","print(\"Final recall score is:\\n\", recall_score(y_test, test_pred['pred']))\n","print(\"Final precision score is:\\n\", precision_score(y_test, test_pred['pred']))\n","print(\"Final accuracy score is:\\n\", accuracy_score(y_test, test_pred['pred']))\n","print(\"Final AUC score is:\\n\", roc_auc_score(y_test, test_pred['pred']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["on test:\n","final recall score is:\n"," 0.9274413529732679\n","final precision score is:\n"," 0.6376594148537135\n","final accuracy score is:\n"," 0.7336403296170625\n","final AUC score is:\n"," 0.7530795949340827\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DQt5SCr0V0-c","colab_type":"code","colab":{}},"source":["# Join with original dataset\n","all_pred = best_model.predict(data_dmatrix)\n","\n","# Predict using best model\n","all_pred = pd.DataFrame(all_pred)\n","all_pred = pd.concat([json, all_pred], axis = 1)\n","\n","all_pred['pred'] = all_pred[0].apply(lambda x: 0 if x < 0.2 else 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AG0frNvmV0-t","colab_type":"code","colab":{}},"source":["# Create Paul exhibit\n","json[['industry_id_x', 'industry_id_y', 'sustainability_dimension', \n","     'company_ticker']].head()\n","\n","json['industry_id_x'].value_counts()\n","json['disclosure_topic_name'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePjonVw5V0-2","colab_type":"code","colab":{}},"source":["# Import and merge on industry names\n","os.chdir(path)\n","inds = pd.read_csv(\"industry.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PEVN9VoSV0_A","colab_type":"code","colab":{}},"source":["# Munge for Paul exhibit\n","predex = all_pred.groupby(['industry_id_x','relevance_assessment']).agg({'pred' : 'sum'})\n","predex['share_disc'] = predex.groupby(['industry_id_x'])['pred'].transform(lambda x: x/x.sum())\n","predex = pd.merge(predex.reset_index(), inds, left_on = 'industry_id_x', right_on = 'INDUSTRY_ID')\n","\n","# Visualize\n","predex[(predex[\"relevance_assessment\"] == \"Relevant\")].sort_values('industry_id_x').plot.bar('INDUSTRY_NAME', 'share_disc', rot = 90, color = 'SECTOR_ID')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBUZUXb4V0_E","colab_type":"code","colab":{}},"source":["# Export predictions\n","predex[['industry_id_x', 'INDUSTRY_NAME']].drop_duplicates().to_csv(\"hcm_materiality_empty.csv\")"],"execution_count":null,"outputs":[]}]}